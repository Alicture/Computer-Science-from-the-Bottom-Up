##内存

###内存层次结构

CPU只能直接从处理器芯片上的高速缓存存储器中获取指令和数据。缓存内存必须从主系统内存(随机访问存储器，或RAM)加载。但是，RAM只在电源打开时才保留其内容，因此需要存储在更永久的存储上。

我们将这些内存层称为_内存层次结构_。

表3.1 内存层次

| 速度  | 内存  |  描述 |
| ------------ | ------------ | ------------ |
| 最快的  | 缓存（Cache）  |  缓存内存实际上是嵌入在CPU中的内存。缓存内存非常快，通常只需要一次周期访问，但是由于它直接嵌入到CPU中，所以它的大小是有限的。事实上，有几个子级别的高速缓存存储器(称为L1，L2，L3)，它们的速度都略有提高。 |
|   | RAM  | 处理器的所有指令和存储地址必须来自RAM。虽然RAM非常快，但CPU访问它仍然需要一些时间(这称为_LYONE_)。RAM存储在独立的专用芯片上，连接到主板上，这意味着它比缓存内存大得多。  |
| 最慢的  | 磁盘  |  我们都熟悉从软盘或光盘获取软件，保存我们的文件到硬盘。我们也熟悉程序从硬盘加载所需的很长时间--具有旋转磁盘和移动磁头等物理机制意味着磁盘是最慢的存储形式。但它们也是迄今为止最大的存储形式。 |

了解内存层次结构的重要一点是速度和大小之间的权衡--越快的内存越小。当然，如果你能找到改变这个方程式的方法，你最终会成为亿万富翁！

缓存之所以有效，是因为计算机代码通常展现出两种形式的局部性。

1. _空间_局部性表示，块内的数据很可能一起访问。

2. _时间_局部性表明最近使用的数据很可能很快就会再次使用。

这意味着，通过尽可能快地实现存储小块相关信息(空间)的可访问内存(时态)，可以获得好处。

##深入缓存

缓存是CPU体系结构中最重要的元素之一。要编写高效的代码，开发人员需要了解其系统中的缓存是如何工作的。

高速缓存是较慢的主系统内存的一个非常快速的副本。高速缓存比主存储器小得多，因为它包含在处理器芯片内，与寄存器和处理器逻辑一起。这是计算机术语中的汤臣一品（译者：比喻为房地产生意，寸土寸金），对其最大规模也有经济和物理限制。随着制造商找到越来越多的方法将越来越多的晶体管塞到芯片缓存中，尺寸也有了很大的增长，但即使最大的缓存也是数十兆字节，而不像普通的主存有着上GB或硬盘的TB级别。

缓存由小块的镜像内存组成。这些块的大小称为_行大小_，通常类似于32或64个字节。在谈到缓存时，通常会讨论行大小，或者是指镜像内存块的缓存行。缓存只能加载和存储大小为缓存行倍数的内存。

缓存有自己的层次结构，通常称为L1、L2和L3。L1缓存是最快和最小的，L2是越来越大，L3更慢。

L1缓存通常被进一步分成指令缓存和数据，被称为“哈佛架构”，是继基于中继的哈佛马克-1计算机引入它之后。拆分缓存有助于减少管道瓶颈，因为早期的管道阶段倾向于引用指令缓存，而后期阶段则是数据缓存。除了减少对共享资源的争用之外，为指令提供单独的缓存还允许替代实现，这些实现可能利用指令流的特性；它们是只读的，因此不需要昂贵的片上功能，例如多移植，也不需要处理子块读取，因为指令流通常使用更规则的大小访问。

图3.4 缓存关联

<span id="CacheAssociativity">

![](https://www.bottomupcs.com/chapter02/figures/sets.png)

给定的高速缓存行可以在其中一个阴影项中找到有效的归属。

在正常操作期间，处理器不断要求缓存检查某个特定地址是否存储在缓存中，因此高速缓存需要一些方法来非常快速地查找它是否存在有效行。如果在缓存中的任何地方都可以缓存给定的地址，则每次引用时都需要搜索每一行缓存行，以确定命中或误操作。为了保持快速搜索，这是在缓存硬件中并行完成的，但是搜索每个条目通常太昂贵，无法一个合理大小的缓存上实现。因此，通过对特定地址必须驻留的位置实施限制，可以简化缓存。这是一种权衡；缓存显然比系统内存小得多，因此某些地址必须要_别名_否则。如果两个彼此别名的地址被不断更新，那么它们被称为_争夺_缓存行。因此我们可以把缓存大致分为三类，就像[图3.4 缓存关联](#CacheAssociativity)中展示的一样。

* _直接映射_缓存允许缓存行仅存在于缓存中的单个条目中。这在硬件中是最容易实现的，但是就像[图3.4 缓存关联](#CacheAssociativity)中展示的一样，因为两个阴影地址必须共享相同的缓存行，所以不存在避免别名的可能性。

* _完全关联_缓存将允许缓存行存在于缓存的任何条目中。这避免了混叠的问题，因为任何条目都可以使用。但是在硬件中实现是非常昂贵的，因为必须同时查找每个可能的位置，以确定值是否在缓存中。

* _组关联_缓存是直接和完全关联缓存的混合体，并允许在缓存中的某些行中存在特定的缓存值。缓存被划分为称为_路_的偶数间隔，并且可以以任何方式定位特定的地址。因此一个n-路组关联缓存允许一个缓存行存在与大小为总块数mod n的任意条目里——[图3.4 缓存关联](#CacheAssociativity)展示了一个8元素，4路组关联缓存；在这种情况下，两个地址有四个可能的位置，这意味着在查找时只有一半的缓存必须被搜索。路数越多，可能的地点越多和别名就会越少，导致整体更好的性能。




一旦缓存满了，处理器就需要去掉一行，为新行腾出空间。有许多算法可供处理器选择要删除的行；例如，_最近最久未使用_(LRU)是一种算法，其中最老的未使用的行被丢弃，以便为新行腾出空间。

当数据仅从缓存中读取时，不需要确保与主内存的一致性。但是，当处理器开始编写缓存行时，它需要就如何更新底层主内存做出一些决定。当处理器更新缓存时，直写缓存直接将更改写入主系统内存。这是比较慢的，因为写入主内存的过程，正如我们所看到的，更慢。另一种方法是，写回缓存延迟将更改写入RAM，直到绝对必要为止。最明显的优点是在编写缓存条目时需要较少的主内存访问。已写入但未提交给内存的缓存行称为_脏_。缺点是，当缓存项被删除时，可能需要两次内存访问(一个用于把脏数据写入主内存，另一个用于加载新数据)。

如果一个条目同时存在于较高级别和较低级别的缓存中，则我们认为较高级别的缓存是_包含性的_。或者，如果具有一行的较高级别缓存消除了较低级别缓存具有该行的可能性，则我们将其称为_排斥的_。这一选择将在[“SMP系统中的缓存独占性”]()一节中进一步讨论。

###缓存寻址

到目前为止，我们还没有讨论缓存是如何决定给定地址是否驻留在缓存中的。显然，缓存必须保存当前缓存行中数据的目录。高速缓存目录和数据可能位于处理器上，但也可能是分开的--例如POWER 5处理器，它有一个核心L3目录，但实际上访问数据需要遍历L3总线来访问离核内存。这样的安排可以促进更快的命中/错过处理，避开了把整个缓存放置在核心上的成本。

图3.5 缓存标签

<span id="CacheTag">

![](https://www.bottomupcs.com/chapter02/figures/tags.png)

需要并行检查标记，以保持较低的延迟时间；更多的标记位(即较少的组相关性)需要更复杂的硬件才能实现这一点。或者，更多的组关联意味着更少的标记，但是处理器现在需要硬件来复用多个组的输出，这也会增加延迟。

要快速确定地址是否位于缓存中，它将分为三部分;标签和索引以及偏移量。

偏移位取决于缓存的行大小。例如，32字节行大小将使用地址的最后5位(即$${2^5}$$)作为行的偏移量。

_index_是条目可能驻留的特定缓存行。例如，让我们假设一个包含256个条目的缓存。如果这是一个直接映射的缓存，我们知道数据可能只驻留在一条可能的行中，因此偏移位后的下一个8位($${2^8}$$)描述了要检查0到255之间的行。

现在，假设相同的256个元素缓存，但分为两路。这意味着有两组128行，并且给定的地址可以驻留在这两个组中的任何一个。因此，只需要7位作为进入128条目路的偏移位索引。对于给定的缓存大小，随着路数数量的增加，由于每一路都变得更小，我们减少了索引所需的位数。

缓存目录仍然需要检查存储在缓存中的特定地址是否是它感兴趣的地址。因此，地址的其余位是_标签位_，缓存目录根据传入的地址标记位进行检查，以确定是否有缓存命中。这种关系在[图3.5“缓存标记”](#CacheTag)中得到了说明。

当有多路时，这种检查必须在每一路中并行进行，然后将其结果传递给一个多路复用器，该复用器输出最后的_命中_或_未命中_结果。如上所述，缓存关联越多，索引所需的位数就越少，标志位的位数就越多--对于一个完全关联的缓存的极端情况，其中没有位作为索引位。标签位的并行匹配是缓存设计中昂贵的组成部分，通常也是限制缓存增长多少行(即大小)的因素。
