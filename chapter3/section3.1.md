#第三章 计算机体系结构

##CPU

图3.1 CPU

![](https://www.bottomupcs.com/chapter02/figures/computer.png)

CPU对寄存器中保存的值执行指令。此示例首先显示将R1的值设置为100，将值从内存位置0x100加载到R2，将两个值相加，并将结果放在R3中，最后将新值(110)存储到R4(供进一步使用)。




为了大大简化，计算机由一个中央处理单元(CPU)连接到内存上。上图说明了所有计算机操作的一般原则。

CPU执行从内存中读取的指令。有两类指令

1. 从内存到寄存器的_读取_数值和从寄存器到内存的_存储_数值。

2. 对存储在寄存器中的值进行操作的。例如，在两个寄存器中加、减、乘或除以值，执行按位运算(和，或，xor等)或执行其他数学运算(平方根、sin、cos、tan等)。




因此，在这个例子中，我们只是简单地将100添加到存储在内存中的值，并将这个新结果存储回内存中。

##分支

除了加载或存储之外，CPU的另一个重要操作是_分支_。在内部，CPU保存要在_指令指针_中执行的下一个指令的记录。通常，指令指针会递增，以顺序指向下一条指令；分支指令通常会检查特定寄存器是否为零，或者是否设置了标志，如果是，则会将指针修改为不同的地址。因此，下一个要执行的指令将来自程序的不同部分；这就是循环和决策语句的工作方式。

例如，像`if(x=0)`这样的语句可以通过找到两个寄存器的`or`来实现，一个寄存器持有`x`，另一个寄存器为零；如果结果为零，则比较为真(即所有`x`位为零)，并且语句的正文应被接受，否则将分支到主体代码之上。

##循环

我们都熟悉计算机的速度，以兆赫兹或千兆赫兹表示(每秒数以百万或数十亿次计)。这称为时钟速度，因为它是计算机内部时钟脉冲的速度。

在处理器内部使用脉冲保持内部同步。在每一个滴答或脉搏上，可以开始另一个操作；把时钟想象成打鼓的人，以保持划桨者的桨同步。

##获取，解码，执行，存储

执行一条指令包括一个特定的事件周期：获取、解码、执行和存储。

例如，要在CPU上执行`add`指令，必须

1. 获取：将指令从内存中输入处理器。

2. 解码：内部解码它必须做的事情(在本例中是添加)。

3. 执行：从寄存器中获取值，将它们相加在一起

4. 存储：将结果存储回另一个寄存器。您可能还会看到术语_retiring _指令。




###查看CPU内部

在CPU内部，有许多不同的子组件执行上述每个步骤，通常它们都可以独立地执行。这类似于一条物理生产线，在那里有许多站点，每个步骤都有一个特定的任务要执行。一旦完成，它就可以将结果传递给下一个站点，并接受一个新的输入来工作。

图3.2 CPU内部

<span id="CPUinside">
	
![](https://www.bottomupcs.com/chapter02/figures/block.png)

CPU由许多不同的子组件组成，每个子组件执行一个专用任务.




[图3.2“CPU中”](#CPUinside)显示了一个非常简单的框图，说明了现代cpu的一些主要部分。

您可以看到指令进入并被处理器解码。CPU有两种主要类型的寄存器，一种是用于_INTEGER_计算所用的，另一种是用于浮点计算的。浮点是一种以二进制形式表示小数位数的方法，在CPU中处理方式不同。_MMX_(多媒体扩展)和_SSE_(流式单指令多数据)或_Altivec_寄存器类似于浮点寄存器。

寄存器文件_是CPU内部寄存器的总称。下面是CPU的各个部分，它们真正地完成了所有的工作。

我们说过，处理器要么将值加载或存储到寄存器中，要么从寄存器存储到内存中，或者对寄存器中的值执行一些操作。

算术逻辑单元(ALU)是CPU操作的核心。它接受寄存器中的值，并执行CPU能够执行的多种操作。所有现代处理器都有许多ALU，因此每个处理器都可以独立工作。事实上，像奔腾这样的处理器有_FAST_和_SLOW_ ALU；快速的处理器比较小(所以您可以在CPU上容纳更多的处理器)，但是只能执行最常见的操作，慢ALU可以执行所有的操作，但是更大。

地址生成单元(AGU)处理与缓存和主内存的对话，以便将值输入寄存器中，以便ALU操作，并将寄存器中的值返回到主内存中。

浮点寄存器有相同的概念，但对其组件使用的术语略有不同。

### 流水线

正如我们上面所看到的，当ALU将寄存器加在一起时，完全独立于AGU将值写回内存，所以CPU没有理由不能同时完成这两项任务。我们在系统中还有多个ALU，每个ALU可以处理不同的指令。最后，CPU可以使用其浮点逻辑执行一些浮点操作，而整数指令也在运行。这个过程被称为_流水线_[^5]，能够这样做的处理器被称为_超标量体系结构_。所有的现代处理器都是超标量的。

另一个类比可能是把管道想象成一个充满弹珠的软管，我们的弹珠是CPU的指令。理想情况下，你会把你的弹珠放在一端，一个接一个(每个时钟脉冲)，填满管子。一旦满了，你推入每一个弹珠(指示)将会把所有其他弹珠移动到下一个位置，终点的一个将掉出(结果)。

但是，分支指令会对这个模型造成破坏，因为它们可能会或不会导致执行从不同的地方开始。如果您是管道，您将必须基本上猜测哪个分支将走向，所以您知道哪些指令要引入到管道中。[^6]相反，如果处理器预测错误，则浪费大量时间，必须清除管道，然后重新启动。

这一过程通常被称为_管道冲洗_,停止以及从您的软管中清空您的所有弹珠！

####分支预测

管道冲洗，预测接受，预测不接受，分支延迟槽

###重新排序

这个bit是垃圾

事实上，如果CPU是软管，它可以自由地重新排序软管内的弹珠，只要它们弹出的顺序与你放进去的顺序相同。我们称之为这个_程序顺序_，因为这是指令在计算机程序中给出的顺序。

图3.3 重新排序缓冲区示例
<span id="reorder">
```
1：R3=R1*R2 
2：R4=R2+R3 
3：R7=R5*R6 
4：R8=R1+R7

```




考虑一个指令流，如[图3.3，“重新排序缓冲区示例”](#reorder)指令2需要等待指令1完全完成才能启动。这意味着管道在等待要计算的值时必须是_START_。类似地，指令3和4依赖于_R7_。但是，指令2和指令3根本不相互依赖；这意味着它们在完全独立的寄存器上运行。如果我们交换指令2和3，我们可以得到一个更好的排序管道，因为处理器可以做有用的工作，而不是等待管道完成，以获得以前的指令的结果。

但是，当编写非常低级别的代码时，一些指令可能需要一些关于操作排序的安全性。我们将此要求称为_内存语义_。如果您需要_获取_语义，这意味着对于这个指令，您必须确保所有先前指令的结果已经完成。如果您需要_释放_语义，您是说在此之后的所有指令都必须看到当前的结果。另一个更严格的语义是一个_内存屏障_ 或_内存栅栏_它要求操作在继续之前已经提交到内存中。

在某些体系结构上，这些语义由处理器为您提供保证，而在另一些体系结构上，您必须显式地指定它们。大多数程序员不需要直接担心它们，尽管您可能会看到这些术语。

##CISC v RISC

划分计算机体系结构的一种常见方法是将计算机划分为_复合指令集计算机_(CISC)和_精简指令集计算机_(RISC)。

注意在第一个示例中，我们已经显式地将值加载到寄存器中，执行了一个加法，并将保存在另一个寄存器中的结果值返回到内存中。这是RISC计算方法的一个例子--仅对寄存器中的值执行操作，并显式地将值加载和存储到内存中。

CISC方法可能只是从内存中获取值的单个指令，在内部执行加法并将结果写回。这意味着指令可能需要很多周期，但最终两种方法都实现了相同的目标。

所有现代体系结构都将被认为是RISC体系结构[^7]。

这有很多原因。

* 尽管RISC使组装编程变得更加复杂，因为几乎所有程序员都使用高级语言，而将生成汇编代码的艰苦工作留给编译器，所以其他优点大于这个缺点。

* 由于RISC处理器中的指令要简单得多，所以芯片内有更多的寄存器空间。从内存层次结构中我们知道，寄存器是最快的内存类型，最终所有指令都必须对寄存器中的值执行，所以所有其他条件相同的情况下，更多的寄存器将导致更高的性能。

* 由于所有指令都在同一时间执行，因此可以执行流水线操作。我们知道流水线需要不断地将指令流输入处理器，因此，如果一些指令需要很长时间而其他指令不需要，则流水线就变得非常复杂。




###EPIC

Itanium处理器，这本书在许多例子中使用的是它，是一个被称为显式并行指令计算的修改架构的例子。

我们讨论了超标量处理器是如何在处理器的不同部分同时具有多条指令的管道的。显然，要想使这一功能尽可能好地发挥作用，处理器就应该给指令一个能够充分利用CPU可用元素的顺序。

传统上，组织传入指令流是硬件的工作。指令是由程序按顺序发出的；处理器必须向前看，并尝试就如何组织传入指令作出决定。

EPIC背后的理论是，在更高的层次上有更多的信息可以比处理器更好地做出这些决定。像当前处理器一样，分析汇编语言指令流会丢失程序员在原始源代码中提供的大量信息。把它看作是研究莎士比亚戏剧和阅读简化版本的区别。两者都给你同样的结果，但原始有各种额外的信息，设置场景，让你洞察人物。

因此，排序指令的逻辑可以从处理器移动到编译器。这意味着编译器编写人员需要更聪明地尝试为处理器找到最佳的代码排序。处理器也大大简化了，因为它的许多工作已经转移到编译器上了[^8]。

---

[^5]: 事实上，任何现代处理器都有许多超过四个阶段可以处理，上面我们只显示了一个非常简单的观点。同时执行的阶段越多，管道就越深。

[^6]: 像奔腾这样的处理器使用一个_TRACE缓存_来跟踪分支的运行方式。很多时候，它可以通过记住以前的结果来预测一个分支的方向。例如，在发生100次的循环中，如果您记得分支的最后结果，您将正确地执行99次，因为只有最后一次才会继续执行程序。

[^7]:  即使是最常见的架构，Intel Pentium，虽然有一个指令集被归类为CISC，但在执行之前，在内部将指令分解为RISC样式的子指令。

[^8]: EPIC周围常使用的另一个术语是超长指令世界(VLIW)，在这里，对处理器的每条指令都会被扩展，以告诉处理器它应该在其内部单元中执行指令的位置。这种方法的问题是代码完全依赖于已经编译完毕的处理器的型号。公司总是对硬件进行修改，让客户每次都重新编译他们的应用程序，并且维护一系列不同的二进制文件是不切实际的。

EPIC以通常的计算机科学方式通过增加抽象层来解决这个问题。EPIC没有显式地指定指令应该在其上执行的处理器的确切部分，而是创建了一个具有几个核心单元(如内存、整数和浮点数)的简化视图。